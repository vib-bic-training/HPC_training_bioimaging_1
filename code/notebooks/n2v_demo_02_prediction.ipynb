{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Void - 2D Example for SEM data\n",
    "\n",
    "__Note:__ This notebook expects a trained model and will only work if you have executed the `01_training.ipynb` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all our dependencies.\n",
    "from n2v.models import N2V\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tifffile import imread\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files to analyze\n",
    "input_folder = '/dodrio/scratch/projects/2024_300/training/n2v/'\n",
    "output_folder = '/dodrio/scractch/projects/2024_300/<YOUR_NAME>/nv2' #TO CHANGE\n",
    "model_folder = os.path.join(output_folder, 'model')\n",
    "file_extension = 'tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A previously trained model is loaded by creating a new N2V-object without providing a 'config'.  \n",
    "model_name = 'n2v_2D_sem'\n",
    "#basedir = 'models'\n",
    "model = N2V(config=None, name=model_name, basedir=model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you do not want to load the weights that lead to lowest validation loss during \n",
    "# training but the latest computed weights, you can execute the following line:\n",
    "\n",
    "# model.load_weights('weights_last.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Here we will simply use the same data as during training and denoise it using our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(input_folder+'/*.'+file_extension)\n",
    "files.sort()\n",
    "\n",
    "if os.path.isdir(output_folder)==False:\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "img=None\n",
    "pred=None\n",
    "\n",
    "stack_min= np.finfo(np.float32).max\n",
    "stack_max = -1\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    basename = os.path.basename(file)\n",
    "    basename_witout_extension = basename[0:-(len(file_extension)+1)]\n",
    "    img = imread(file)\n",
    "\n",
    "    # Here we process the data.\n",
    "    # The 'n_tiles' parameter can be used if images are too big for the GPU memory.\n",
    "    # If we do not provide the 'n_tiles' parameter the system will automatically try to find an appropriate tiling.\n",
    "    pred = model.predict(img, axes='YX', n_tiles=(2,1))\n",
    "\n",
    "    min = pred.min()\n",
    "    if(min<stack_min):\n",
    "        stack_min=min\n",
    "    max = pred.max()\n",
    "    if(max>stack_max):\n",
    "        stack_max=max\n",
    "\n",
    "    save_tiff_imagej_compatible(os.path.join(output_folder,basename_witout_extension+'_denoised.tif'), pred, 'YX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to 16bits\n",
    "print('Max:'+str(stack_max))\n",
    "print('Min:'+str(stack_min))\n",
    "\n",
    "rescale_folder = os.path.join(output_folder, '16bits')\n",
    "\n",
    "files = glob.glob(output_folder+'/*.'+file_extension)\n",
    "files.sort()\n",
    "\n",
    "if os.path.isdir(rescale_folder)==False:\n",
    "    os.makedirs(rescale_folder)\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    basename = os.path.basename(file)\n",
    "    basename_witout_extension = basename[0:-(len(file_extension)+1)]\n",
    "    pred = imread(file)\n",
    "    pred_16 = (pred / stack_max) * 65536 #2^16\n",
    "    pred_16 = pred_16.astype(np.uint16) \n",
    "    save_tiff_imagej_compatible(os.path.join(rescale_folder,basename_witout_extension+'.tif'), pred_16, 'YX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the results.\n",
    "# Show a 500x500 crop of the image before and after\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[:500:,:500],cmap=\"gray\")\n",
    "plt.title('Input');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pred[:500:,:500],cmap=\"gray\")\n",
    "plt.title('Prediction');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-n2v_lf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
